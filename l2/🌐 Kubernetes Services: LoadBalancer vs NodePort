ğŸ¬ Introduction
Welcome back to the Kubernetes journey!


In the previous session, we explored the NodePort service type, which helps us expose applications running inside the Kubernetes cluster to the outside world through a specific port on each node.

But now, letâ€™s step into the real-world scenario of hosting applications in the cloud. This brings us to a more powerful service type: the LoadBalancer.

âš¡ Why LoadBalancer?
Think about real websites you visit every day:

Google.com â†’ no port number in the URL.

YouTube.com â†’ again, no port numbers.

You never see something like:

www.example.com:30080

Thatâ€™s because exposing applications on high random ports (like NodePort does) is:

âŒ Bad user experience
âŒ Hard to remember
âŒ Security risk

Instead, production-grade systems use a LoadBalancer service which exposes applications directly on standard ports:

80 â†’ HTTP
443 â†’ HTTPS

ğŸ” The Role of Cloud in LoadBalancer


Hereâ€™s where the magic happens.

When you create a Kubernetes LoadBalancer service, it doesnâ€™t directly spin up a load balancer. Instead:

Service Type = LoadBalancer is defined in YAML.
Kubernetes forwards this request to the Cloud Controller Manager (CCM).
The CCM talks to the Cloud Provider API (AWS, GCP, Azure, etc.).

The cloud provider provisions a real load balancer instance (e.g., AWS ELB, GCP Cloud LB).

Your service is exposed with an External IP Address.

ğŸ“Œ On local clusters like Minikube or Kind, there is no cloud provider, so Kubernetes cannot actually create a cloud load balancer. Instead, the external IP stays in Pending state.

âš”ï¸ NodePort vs LoadBalancer
Feature	NodePort	LoadBalancer

Exposed On	Random high port (e.g., 30080)	Standard ports (80, 443)
User Experience	http://<node-ip>:30080	http://<domain.com>
Requires Cloud Provider?	âŒ No	âœ… Yes
Production Ready?	âŒ Not recommended	âœ… Yes
Common Use Case	Local testing, demos	Cloud deployments

ğŸ›  YAML Example
NodePort Service

apiVersion: v1
kind: Service
metadata:
  name: nginx-nodeport
spec:
  type: NodePort
  selector:
    app: nginx
  ports:
    - port: 80
      targetPort: 80
      nodePort: 30080
LoadBalancer Service

apiVersion: v1
kind: Service
metadata:
  name: nginx-lb
spec:
  type: LoadBalancer
  selector:
    app: nginx
  ports:
    - port: 80
      targetPort: 80


ğŸ‘‰ Notice the difference:

NodePort explicitly mentions nodePort.
LoadBalancer only requires the standard port (Kubernetes + Cloud take care of the rest).

ğŸ§ª Demo on Minikube

Letâ€™s test it locally with Minikube.

Delete any existing service:

kubectl delete svc nginx-nodeport
Apply the LoadBalancer service:

kubectl apply -f lb.yaml
Check services:

kubectl get svc

Output:

NAME         TYPE           CLUSTER-IP    EXTERNAL-IP   PORT(S)   AGE
nginx-lb     LoadBalancer   10.96.12.34   <pending>     80/TCP    10s
ğŸ“Œ Here, EXTERNAL-IP is Pending because Minikube is not connected to a cloud.

ğŸŒ€ Minikube Tunnel (Simulation)

Minikube provides a workaround by creating a tunnel:

minikube tunnel
This maps the LoadBalancer service to a port on your localhost, effectively simulating how a real load balancer would expose it.

ğŸ¯ Key Takeaways


NodePort â†’ quick and dirty exposure (good for local/dev).
LoadBalancer â†’ production-grade service (good for cloud).

On local clusters (Minikube/Kind), LoadBalancer behaves like NodePort + Tunnel.

On cloud (EKS, GKE, AKS), LoadBalancer provisions a real cloud load balancer.

ğŸ¥ Closing Note
Think of it like this:

NodePort is like shouting from your balcony to tell people youâ€™re home.

LoadBalancer is like having a proper doorbell + address board in a nice neighborhood where anyone can find you.

In the next stage of your Kubernetes journey, when we explore cloud providers, weâ€™ll see the true power of LoadBalancer services in action. ğŸš€
