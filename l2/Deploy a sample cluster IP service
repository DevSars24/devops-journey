
Introduction
Welcome to an exciting exploration of Kubernetes services! In this documentary, we'll dive into a practical demonstration of creating a Kubernetes service, understand its importance, and see what happens when we donâ€™t use one. Guided by Piyush, our expert instructor, weâ€™ll break down complex concepts into simple, digestible explanations, enriched with signs, symbols, tables, and charts. Letâ€™s embark on this journey to demystify Kubernetes services!

Scene 1: Setting the Stage
Piyush begins the lecture with enthusiasm, ready to demonstrate how to create a Kubernetes service. Letâ€™s follow along as he shares his screen and walks us through a sample deployment YAML file.
Line Explanation: â€œSo this is a sample deployment YAML that I have used in one of the previous videos.â€

Simple Explanation: Piyush is showing us a configuration file (called a YAML file) that tells Kubernetes how to set up an application. Itâ€™s like a recipe for deploying software in Kubernetes.
Visual Aid: 
Symbol: ğŸ“œ (Represents a configuration file)
Table: Structure of a YAML File


Field
Description



apiVersion
Version of Kubernetes API used


kind
Type of resource (e.g., Deployment)


metadata
Information like name and labels


spec
Specifications for the resource (e.g., replicas, containers)



Scene 2: Understanding the Deployment
Piyush explains the components of the deployment YAML file, which sets up three replicas of an NGINX container.
Line Explanation: â€œThis is pretty much the same thing. So we have three replicas and we have nginx image used and we have an NGINX container.â€

Simple Explanation: The YAML file instructs Kubernetes to create three copies (replicas) of an NGINX web server container. NGINX is a popular software for hosting websites.
Visual Aid: 
Symbol: ğŸ–¥ï¸ (Represents a server/container)
Chart: Deployment Structure



graph TD
    A[Deployment] --> B[Replica 1: NGINX]
    A --> C[Replica 2: NGINX]
    A --> D[Replica 3: NGINX]


Scene 3: Adding Container Ports
Piyush adds a port configuration to the YAML file to make the NGINX container accessible.
Line Explanation: â€œLet's add the container ports as well. So over here you see we can add a field called ports and then specify the container port with the number 80.â€

Simple Explanation: Port 80 is like a door that allows traffic to enter the NGINX container. By specifying it in the YAML, Kubernetes knows to open this door.
Visual Aid: 
Symbol: ğŸšª (Represents a port)
Table: Port Configuration

Field
Value
Description

ports

List of ports to expose


containerPort
80
Port number for NGINX (HTTP)

Scene 4: Publishing the Container
Piyush explains the significance of exposing the container on port 80.
Line Explanation: â€œSo what it is actually doing, it is actually publishing the container, this particular container on port 80.â€

Simple Explanation: Publishing on port 80 means the NGINX container is ready to receive web traffic, just like a website accessible via a browser.
Visual Aid: 
Symbol: ğŸŒ (Represents web access)
Chart: Container Communication



graph LR
    A[External Request] --> B[Port 80] --> C[NGINX Container]


Scene 5: Comparing to Docker
Piyush draws a parallel between Kubernetes and Docker for better understanding.
Line Explanation: â€œLike how we were exposing port inside the container when we were using just the docker container without kubernetes. It is basically doing the same thing.â€

Simple Explanation: In Docker, we also open ports to allow access to containers. Kubernetes does the same, but it manages multiple containers and adds extra features.
Visual Aid: 
Symbol: âš™ï¸ (Represents configuration similarity)
Table: Docker vs. Kubernetes Port Exposure

Feature
Docker
Kubernetes



Port Exposure
docker run -p 80:80
containerPort: 80 in YAML


Management
Manual
Automated via Deployment



Scene 6: Applying the YAML File
Piyush attempts to apply the YAML file but encounters an error.
Line Explanation: â€œOkay, now if I just save the file and let's apply this file. So kubectl apply hyphen f and deploy YAML, it says resource name must not be empty.â€

Simple Explanation: Piyush uses the kubectl apply command to tell Kubernetes to create the deployment. However, an error occurs because something is wrong in the YAML file.
Visual Aid: 
Symbol: âŒ (Represents an error)
Table: Common kubectl apply Errors


Error Message
Possible Cause

Resource name must not be empty
Missing metadata.name in YAML


Invalid indentation
Incorrect spacing in YAML file

Scene 7: Fixing the Indentation
Piyush identifies and corrects an indentation issue in the YAML file.
Line Explanation: â€œI might have missed something. So let's see API version metadata and I believe there is an indentation issue over here.â€

Simple Explanation: YAML files are sensitive to spaces (indentation). Piyush notices the name and labels fields are not properly aligned under metadata.
Visual Aid: 
Symbol: ğŸ“ (Represents alignment)
Code Snippet: Corrected YAML Structure



apiVersion: apps/v1
kind: Deployment
metadata:
  name: nginx-deployment
  labels:
    app: nginx
spec:
  replicas: 3
  selector:
    matchLabels:
      app: nginx
  template:
    metadata:
      labels:
        app: nginx
    spec:
      containers:
      - name: nginx
        image: nginx
        ports:
        - containerPort: 80


Scene 8: Reapplying the Deployment
With the issue fixed, Piyush reapplies the YAML file successfully.
Line Explanation: â€œSo let's apply the changes again. And yes it's created so cube CTL get deploy and it's still coming up.â€

Simple Explanation: After fixing the YAML, Piyush runs kubectl apply again, and the deployment is created. He checks its status with kubectl get deploy.
Visual Aid: 
Symbol: âœ… (Represents success)
Chart: Deployment Status



graph TD
    A[Apply YAML] --> B[Deployment Created]
    B --> C[Check Status: kubectl get deploy]


Scene 9: Monitoring in Real-Time
Piyush uses a command to monitor the deployment in real-time.
Line Explanation: â€œSo let's wait, we can add Var to it so that it will be updated and it will be reflected on the screen.â€

Simple Explanation: The --watch (or -w) flag in kubectl get deploy keeps the terminal updated with live changes, like watching a live feed.
Visual Aid: 
Symbol: ğŸ‘€ (Represents watching)
Table: kubectl Commands with Watch




Command
Description



kubectl get deploy -w
Monitor deployment status live


kubectl get pods -w
Monitor pod status live



Scene 10: Checking Pods
Piyush confirms that the deployment has created three pods.
Line Explanation: â€œOkay, so now it, it says it is up and if I just do kubectl get pods all these deployments are running.â€

Simple Explanation: Pods are the smallest units in Kubernetes that run containers. Piyush checks that all three NGINX pods are running using kubectl get pods.
Visual Aid: 
Symbol: ğŸŸ¢ (Represents running status)
Table: Pod Status

Pod Name
Status
IP Address

nginx-deployment-xxx
Running
10.244.1.2


nginx-deployment-yyy
Running
10.244.1.3


nginx-deployment-zzz
Running
10.244.1.4



Scene 11: The Need for a Service
Piyush explains why a service is necessary to access the application.
Line Explanation: â€œDeployment has three parts and let's suppose this is a front end application. This is a web facing application. User has to access this application.â€

Simple Explanation: The deployment runs three NGINX pods, but users canâ€™t access them directly because thereâ€™s no external endpoint. A service is needed to provide access.
Visual Aid: 
Symbol: ğŸŒ (Represents user access)
Chart: Without Service



graph LR
    A[User] -->|No Access| B[Pods: No Endpoint]


Scene 12: Attempting to Access Pods
Piyush tries to access the pods directly but fails.
Line Explanation: â€œOkay, I do see an IP, so let's try to curl the IP on port 80. Any of these IP so curl IP port 80. Okay, I'm not getting any reply back, so is fail to connect.â€

Simple Explanation: Piyush uses the curl command to access a podâ€™s IP on port 80, but it fails because the pod isnâ€™t exposed outside the Kubernetes cluster.
Visual Aid: 
Symbol: ğŸš« (Represents connection failure)
Table: Curl Attempt

Command
Result



curl 10.244.1.2:80
Failed to connect

Scene 13: Localhost Attempt
Piyush tries accessing the application via localhost, which also fails.
Line Explanation: â€œOkay, so local host port 80 and it's still not able to connect because we have not exposed the port or we have not exposed the application to outside the pod or to outside the deployment.â€

Simple Explanation: Trying to access the application on localhost:80 doesnâ€™t work because the pods are internal to the Kubernetes cluster and not exposed externally.
Visual Aid: 
Symbol: ğŸ”’ (Represents locked access)
Chart: Access Attempt

graph LR
    A[User: localhost:80] -->|Blocked| B[Kubernetes Cluster]


Scene 14: Introducing the Service
Piyush introduces the concept of a Kubernetes service to solve the access issue.
Line Explanation: â€œNow for that what we have to do we have to create a service. Right? So we'll start with the basic server. We'll start with the cluster ip.â€

Simple Explanation: A service acts like a bridge, allowing users to access the pods. Piyush starts with a ClusterIP service, which is meant for internal access within the cluster.
Visual Aid: 
Symbol: ğŸŒ‰ (Represents a service bridge)
Table: Service Types

Service Type
Description

ClusterIP
Internal access within cluster


NodePort
Exposes service on nodeâ€™s IP


LoadBalancer
Exposes service externally via cloud

Scene 15: Exposing the Deployment
Piyush uses the kubectl expose command to create a service.
Line Explanation: â€œSo kubectl expose and then the deployment name of the deployment and the port. Okay, so our deployment name is nginx deployment.â€

Simple Explanation: The kubectl expose command creates a service for the NGINX deployment, making it accessible on port 80 within the cluster.
Visual Aid: 
Symbol: ğŸ”“ (Represents exposure)
Code Snippet: Expose Command



kubectl expose deploy nginx-deployment --port=80


Scene 16: Verifying the Service
Piyush checks the newly created service and its details.
Line Explanation: â€œOkay, now it says service exposed. If I do kubectl get service, I see that there is an nginx deployment service of type cluster IP that's been created for you on port 80.â€

Simple Explanation: The service is created successfully, and Piyush uses kubectl get service to confirm itâ€™s a ClusterIP service running on port 80.
Visual Aid: 
Symbol: âœ… (Represents successful creation)
Table: Service Details


Service Name
Type
Cluster IP
Port



nginx-deployment
ClusterIP
10.96.0.1
80



Scene 17: Describing the Service
Piyush explores the serviceâ€™s details using the describe command.
Line Explanation: â€œSo if we describe it, we see now this is exposed on port 80 on the endpoints 10.244.1.3, 10.244.0.3 and 10.244.1.2.â€

Simple Explanation: The kubectl describe svc command shows that the service connects to the podsâ€™ IP addresses (endpoints) on port 80.
Visual Aid: 
Symbol: ğŸ”— (Represents endpoints)
Chart: Service to Pods

graph TD
    A[Service: nginx-deployment] --> B[Pod 1: 10.244.1.2]
    A --> C[Pod 2: 10.244.1.3]
    A --> D[Pod 3: 10.244.0.3]


Scene 18: Understanding Endpoints
Piyush explains that the service connects to the podsâ€™ IP addresses.
Line Explanation: â€œThese are the IP addresses of the pods, if you remember. So if I do kubectl get pods O white.â€

Simple Explanation: The service routes traffic to the podsâ€™ IP addresses, which Piyush confirms by listing the pods with kubectl get pods -o wide.
Visual Aid: 
Symbol: ğŸ›¤ï¸ (Represents routing)
Table: Pod IPs

Pod Name
IP Address



nginx-deployment-xxx
10.244.1.2

nginx-deployment-yyy
10.244.1.3

nginx-deployment-zzz
10.244.0.3



Scene 19: Service as a Frontend
Piyush clarifies the relationship between the service and pods.
Line Explanation: â€œSo now our front end is the service and backend are, the pods. Each of these pods are the backend endpoints of the service.â€

Simple Explanation: The service acts as a front door, receiving requests and sending them to the pods (the backend workers).
Visual Aid: 
Symbol: ğŸ¬ (Represents frontend-backend)
Chart: Service Architecture

graph LR
    A[User] --> B[Service: ClusterIP] --> C[Pod 1]
    B --> D[Pod 2]
    B --> E[Pod 3]


Scene 20: Testing Service Access
Piyush tries to access the service but encounters issues with Minikube.
Line Explanation: â€œOkay, and if I do a curl localhost on 80, it still says unable to connect, but let's try to curl this cluster IP curl.â€

Simple Explanation: Piyush tries to access the service using curl on the ClusterIP, but it fails because Minikube (a local Kubernetes tool) requires additional steps.
Visual Aid: 
Symbol: ğŸš« (Represents connection failure)
Table: Access Attempts

Command
Result

curl localhost:80
Unable to connect


curl <ClusterIP>:80
Could not resolve



Scene 21: Minikubeâ€™s Unique Behavior
Piyush explains why direct access doesnâ€™t work in Minikube.
Line Explanation: â€œNow how do I access this service internally to access the service? Actually, minikube has some extra step.â€

Simple Explanation: Minikube, a tool for running Kubernetes locally, doesnâ€™t allow direct access to ClusterIP services. It uses a tunnel to forward traffic.
Visual Aid: 
Symbol: ğŸ› ï¸ (Represents Minikube)
Chart: Minikube Access



graph LR
    A[User] --> B[Minikube Tunnel] --> C[Service: ClusterIP] --> D[Pods]


Scene 22: Listing Services in Minikube
Piyush uses Minikube commands to explore available services.
Line Explanation: â€œSo what we have to do is we have to use this command minikube service list.â€

Simple Explanation: The minikube service list command shows all services, including the NGINX service Piyush created, and their access details.
Visual Aid: 
Symbol: ğŸ“‹ (Represents listing)
Table: Minikube Service List

Service Name
Type
URL

kubernetes
ClusterIP
None

nginx-deployment
ClusterIP
None

Scene 23: Accessing the Service
Piyush demonstrates how to access the service using Minikube.
Line Explanation: â€œSo to access this service, you can do minikube service and then the name of the service just want the URL of this service.â€

Simple Explanation: The minikube service nginx-deployment --url command provides a URL to access the service locally via a tunnel.
Visual Aid: 
Symbol: ğŸ”— (Represents URL)
Code Snippet: Minikube Command

minikube service nginx-deployment --url

Scene 24: Successful Access
Piyush opens the service in a browser and sees the NGINX welcome page.
Line Explanation: â€œSo if you do that it will open. Right. Welcome to nginx, which is the default homepage of our NGINX container.â€

Simple Explanation: Using the Minikube URL, Piyush accesses the NGINX service in a browser, displaying the â€œWelcome to NGINXâ€ page.
Visual Aid: 
Symbol: ğŸ‰ (Represents success)
Chart: Access Flow

graph LR
    A[User Browser] --> B[Minikube URL: http://localhost:50029] --> C[Service] --> D[NGINX Pods]


Scene 25: Understanding Minikubeâ€™s Port Binding
Piyush explains the port binding created by Minikube.
Line Explanation: â€œAnd it is now exposed on port 50029 because it created a new port binding.â€

Simple Explanation: Minikube assigns a random port (e.g., 50029) to forward traffic to the serviceâ€™s port 80.
Visual Aid: 
Symbol: ğŸ”Œ (Represents port binding)
Table: Port Mapping


External Port
Internal Port
Destination


50029
80
NGINX Service

Scene 26: Wrapping Up
Piyush concludes the demo and previews the next topic.
Line Explanation: â€œOkay, so I guess that's it for this video. In the next video I will see you with the next service Type, which is NodePort, and we'll do the demo of it.â€

Simple Explanation: Piyush wraps up the ClusterIP service demo and promises to cover NodePort, another service type, in the next lecture.
Visual Aid: 
Symbol: ğŸ“º (Represents next video)
Table: Upcoming Topics


Service Type
Description

NodePort
Exposes service on each nodeâ€™s IP

Conclusion
This documentary has taken us through the fascinating world of Kubernetes services, from creating a deployment to exposing it with a ClusterIP service. With Piyushâ€™s guidance, weâ€™ve seen how services act as bridges to connect users to applications, and how tools like Minikube add unique steps for local access. Stay tuned for the next episode, where weâ€™ll explore NodePort services!
Thank you for joining us on this Kubernetes journey. See you in the next video!
